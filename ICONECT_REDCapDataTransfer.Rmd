---
title: "ICONECT_REDCapDataTransfer"
author: "Nicolas May"
date: "2/27/2019"
output: 
  html_document:
    theme: sandstone
    highlight: zenburn
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load Libraries

```{r message=FALSE}
library(dplyr)
# library(stringr) # no longer needed
library(readr)
library(readxl)
library(rlang)
```

### Create Function for Renaming

```{r}
get_new_name <- function(x, df, old_field_name, new_field_name) {
  # Capture passed field names in rlang quosures
  old_field_name <- enquo(old_field_name) 
  new_field_name <- enquo(new_field_name)
  
  df %>% 
    filter(!!old_field_name == x) %>% # unquote quosure
    select(!!new_field_name) %>%      # unquote quosure
    pull()
}
```

-----

-----

-----

# WORKING CASE

## Get Data

Old REDCap Data

```{r}
# Read CSV of original data, coercing all fields' data types to character
df_orig <- 
  read_csv("DATA_OCTRI5793Internetbas_2019-02-05_0659.csv",
           col_types = cols(.default = col_character()))

# Field `mrp_yn` should be dropped from the original dataset
df_orig <- df_orig %>% 
  select(-mrp_yn)
```

Field Harmonization Table

```{r}
# Read XLSX of UDPATED field harmonization table
# This field harmonization table includes dummy fields for expanded
# checkbox fields (e.g., `*___1`, `*___2`, etc.)
df_harm <- 
  read_excel("ICONECT_Variable_Mapping_UPDATED_2019-02-27.xlsx")

# # The filters below are now unnecessary. (2019-02-27)
# # They were based on the original field harmonization table.
# # These issues have been resolved.
# df_harm <- df_harm %>% 
#   # Temporarily remove checkbox fields -- NEED TO RESOLVE
#   filter(!str_detect(`Old Database`, "^trb_re")) %>%
#   filter(!str_detect(`Old Database`, "^tin_rea")) %>%
#   # Temporarily remove any one-to-many (old->new) mappings
#   # evident by spaces between field names:
#   #     a5_loc  =>  arp_loc tnt_loc tpu_loc wkq_loc
#   filter(!str_detect(`New Database`, " "))

# There's a mapping that's reduandant: `a5_loc` => `arp_loc`.
# `arp_loc` already exists, so I'm filtering out the `a5_loc` => `arp_loc`
# row from the `df_harm` table. 
# `arp_loc` will later be propogated/copied to redundant fields:
# `tnt_loc`, `tpu_loc`, `wkq_loc`.
# df_harm <- df_harm %>% 
#   filter(`Old Database` != "a5_loc")
```


## Process Data

Keep only those fields listed in the `Old Database` column of the harmonization table.

```{r}
fields_to_keep <- names(df_orig)[names(df_orig) %in% df_harm$`Old Database`]

df_orig <- df_orig %>% 
  select_at(vars(fields_to_keep))
```


Rename old field names to new field names

```{r}
df_new <- df_orig %>% 
  rename_at(.vars = vars(df_harm$`Old Database`),
            .funs = function(x) {
              get_new_name(x, df_harm, `Old Database`, `New Database`)
            })
```

Propogate `apr_loc` field values to redundant fields: `tnt_loc`, `tpu_loc`, `wkq_loc`

```{r}
df_new <- df_new %>%
  mutate(tnt_loc = arp_loc,
         tpu_loc = arp_loc,
         wkq_loc = arp_loc)
```

Clean out any fields that don't have any values.

```{r}
df_new <- df_new %>% 
  select_if(
    function(x) {
      any(!is.na(x))
    })
```


## Write Data

```{r}
write_csv(df_new, 
          paste0("DATA_TO_IMPORT_", Sys.Date(), ".csv"), 
          na = "")
```

-----

-----

-----


# TEST CASE

## Get Data

TEST Old REDCap Data

```{r}
test_df_orig <-
  tibble(
    a = as.character(1:5),
    b = letters[1:5],
    c = LETTERS[1:5],
    d = sample(1:5, 5)
  )
```

TEST Field Harmonization Table

```{r}
test_df_harm <-
  tibble(
    old = c("a", "b", "c", "d"),
    new = c("a", "e", "f", "d")
  )
```


## Process Data

```{r}
test_df_orig %>% 
  rename_at(.vars = vars(test_df_harm$old),
            .funs = function(x) {
              get_new_name(x, test_df_harm, old, new)
            })
```

-----

-----

-----
